---
layout: default
---

Text can be **bold**, _italic_, or ~~strikethrough~~.

[Link to another page](./another-page.html).

There should be whitespace between paragraphs.

There should be whitespace between paragraphs. We recommend including a README, or a file with information about your project.

# Career Objective

To achieve excellence in working as dynamic professional offering solutions to business using the best available where my analytical ability and analyzing quest are used maximum for growth of the organization and to grow with the organization. Seeing a challenging position in well-established company that offers professional growth and ample opportunity to learn and enrich my competencies in my profession.

## Educational Profile

•	Perusing Msc. In ML and AI from Upgrad India (IIIT, Bangalore and LPJMU)
•	Completed Bachelor of Technology in Electrical Engineering (in 2010) from Biju Patnaik University of Technology (BPUT) Orissa, India.


> This is a blockquote following a header.
>
> When something is important enough, you do it even if the odds are not in your favor.

### Technical Skill Set Summary

Performance Testing:
•	Testing Tools              : HP Load Runner 11.0/9.5, HP Load Runner 12.00/11.52 and HP ALM    
                                    Performance Center 12.00/11.0, Soap UI.
•	Servers		                 : IBM Web sphere 8.5.0.2, Weblogic 10 and Apache Tomcat 6.0.
•	Monitoring Tool            : CA Wily Introscope, DynaTrace, Perfmon, Jconsole, JvisualVM, TDA and Sitescope.
•	Defect Tracking            : Quality Center 12.0/11.0.
•	Other Tool		             : Oracle SQL Developer, Putty



#### Software Skills:

•	Languages     –  Python, JAVA and UNIX
•	OS	          – Windows NT/95/98/2000, Unix.
•	Databases     –  Oracle DB, MS SQL Server
•	Packages      –  MS Office


##### Professional Experience

•	Oracle India Private Limited. since november’2016 to till date as Sr. Performance Engineer
•	JPMorgan Chase & Co, Bangalore (India) since July’2013 to till November 2016 as Performance Engineer.
•	Wipro Limited, Hyderabad (India) since Nov’2010 to June’2013 as Performance Test Engineer.


###### Oracle India Private Limited (Stress Team)

Here Working as Sr. Performance Engineer and role is Individual Contributor. In Oracle stress team worked on various products like OHS, OTD, Web-center, SOA, OSB, Fusion apps.Currentely from past 2 years working in Fusion apps stress team, responsible for many flows end to end performance engineering.

Responsibilities: 
•	Here handling multiple Fusin apps flows and SOA flows end to end. Mostly finding bottlenecks and doing root cause analysis. Once done filing bug and giving performance improvement recommendations, Tuning, like java performance tuning or DB performance tuning….
•	Gather and analyse application performance requirements from development team.
•	Collaborate with Project Managers and developers to define and create test objectives, test environments, and test data requirements for performance test plan.
•	Performance testing of Web (HTTP/HTML) applications, Middleware applications, IVR applications and Citrix applications.
•	Develop performance test scripts using Industry Standard Tools like LoadRunner 12.00/11.5/11 for complex protocol like EJB (Enterprise JavaBeans), Citrix, web services and Web (HTTP/HTML).
•	Preparation and execution of test scripts using LoadRuner and SOAP UI tool to perform Web Services testing.
•	Writes and executes SQL queries for data conditioning and validating test results.
•	Design load, scalability, stress, soaks, failover and volume testing scenarios according to the production usage and for capacity planning as well.
•	Execute performance test using OATS  and monitored the test execution, collected all the required inputs from available resources like online monitors graph, client side matrices i.e. transaction response time, average response time etc.
•	Install and configure monitors for analysis.
•	Perform client side monitoring and server side monitoring during test execution using monitoring tools like , Perfmon, Jconsole, JvisualVM, TDA and Site scope.
•	Monitor Metrics on Application server, Web server and database server.
•	Identify the queries which taking too long and optimize those queries to improve performance.
•	Analyze webserver & application server logs and identify the performance bottlenecks.
•	Generate server performance matrix for application behaviour over Tomcat, Websphere and Weblogic.
•	Determine the bottlenecks of the application (Memory leaks, DB Bottlenecks, Code related performance issues etc.).
•	Investigating Java based application to detect Memory Leaks using variety of java tools.
•	Provide recommendations for hardware for the load anticipated and the target data volume.
•	Provide performance tuning recommendations for improvements.
•	Prepare and published the performance test report.
•	Generate performance monitoring reports for applications in production

### JP Morgan Chase CCB STS & AM TECH (Consumer & Community Banking Shared Technology Services and ASSET MANAGEMENT)

Worked as a Performance Engineer in CCB STS (Consumer & Community Banking Shared Technology Services) and AM TECH (ASSET MANAGEMENT) Performance Engineering Team at JP Morgan Chase and Co.
CCB STS and AM TECH Performance Engineering Team of “JP Morgan Chase and Co” was started to ensure that Information technology services are able to meet the expectations and rigors of production usage, through Performance Testing Services. 
All The applications were tested for End User Experience, Endurance, Capacity types of performance tests, certifying against the pre-determined response times and volumes. Based on the success criteria determined, the tests were conducted in multiple rounds after enhancing the application after each round of test. The Applications are certified by Performance Testing Group as fit for production deployment after all the three types of tests are considered as pass

Responsibilities: 
•	Gather and analyse application performance requirements from development team.
•	Collaborate with Project Managers and developers to define and create test objectives, test environments, and test data requirements for performance test plan.
•	Performance testing of Web (HTTP/HTML) applications, Middleware applications, IVR applications and Citrix applications.
•	Develop performance test scripts using Industry Standard Tools like LoadRunner 12.00/11.5/11 for complex protocol like EJB (Enterprise JavaBeans), Citrix, web services and Web (HTTP/HTML).
•	Preparation and execution of test scripts using LoadRuner and SOAP UI tool to perform Web Services testing.
•	Writes and executes SQL queries for data conditioning and validating test results.
•	Design load, scalability, stress, soaks, failover and volume testing scenarios according to the production usage and for capacity planning as well.
•	Execute performance test using HP Loadrunner Controller and monitored the test execution, collected all the required inputs from available resources like online monitors graph, client side matrices i.e. transaction response time, average response time etc.
•	Install and configure monitors for analysis.
•	Perform client side monitoring and server side monitoring during test execution using monitoring tools like CA Wily Introscope, Perfmon, Jconsole, JvisualVM, TDA and Site scope.
•	Monitor Metrics on Application server, Web server and database server.
•	Identify the queries which taking too long and optimize those queries to improve performance.
•	Analyze webserver & application server logs and identify the performance bottlenecks.
•	Generate server performance matrix for application behaviour over Tomcat, Websphere and Weblogic.
•	Determine the bottlenecks of the application (Memory leaks, DB Bottlenecks, Code related performance issues etc.).
•	Investigating Java based application to detect Memory Leaks using variety of java tools.
•	Provide recommendations for hardware for the load anticipated and the target data volume.
•	Provide performance tuning recommendations for improvements.
•	Prepare and published the performance test report.
•	Generate performance monitoring reports for applications in production


### NG USFP-Performance Testing Project

Project Summary:
The main Objective Measure the performance of the individual identified business processes in sequential manner against pre-defined SLA’s/NFR’s with normal user load per business scenario and measure the performance of the solution and the associated infrastructure against pre-defined SLA’s/NFR’s (E2E and component/application level) under normal and peak loads.

Activities Undertaken In This Project:
•	Unit Performance Verification: here obtained was initial baseline performance metrics such as response times and throughputs of the critical scenarios for the application / system under test. 
•	Baseline: This was to identify the correctness of the scripts and also helped in checking whether the application meets the pre-defined SLAs set by business.
•	Network Latency Test: this was to Simulates real world traffic and activity for the application under test with user load simulated from different locations. Throughout, Stability and responsiveness of the application are measured against expected or required metrics.

Responsibilities: 
•	Gathered Performance requirements for the application and designed performance tests for the multiple clients within the organization.
•	Responsible for implementing LoadRunner, Performance center based infrastructure including: Architecting the load testing infrastructure, hardware & software integration with LoadRunner.
•	Build & enhanced the performance test scripts using SAP WEB, SAP GUI and Citrix Protocol.
•	Developed and Executed the Test cases & scripts for Smoke, System, Regression, and Performance.
•	Designed load and stress testing scenarios.
•	Executed simulation scenarios using HP ALM Performance Center 11.00 Controller.
•	Performed load testing on SAP and Citrix environment.
•	Monitored Metrics on Application server, Web server and database server using Perfmon, Site scope and SAP T-codes.
•	Analyzed the performance test results.
•	Prepared and submit the reports along with the inferences.
•	Provided application performance improvement recommendations.
•	Generated recommendations to the application / infra team by identifying the application hotspots and improving the overall system response times and availability. 
•	Involved in Bug reporting using the bug-tracking tool.


### GE Health Care BACOE Performance Testing Project

Project Summary
The main objective of this Project was to check whether the applications and the related components would be able to perform reliably and as per the expectations under heavy loads of quarter/year-end close. The expectations, simply put, the database server should be able to handle the expected Business transactions along with the Concurrent jobs, Appworx chains, interfaces, and extracts. 
The technology used in GLPROD (11i) was Oracle Applications 11.5.10.2 running on Oracle 10g as the database server and Sun OS 5.10 sun4u sparc SUNW.
And, the technology used in BIOPROD (R12) was Oracle Applications 11.2.0.3.0 running on Oracle 10g as the database server and SunOS erp-ora-stg-02 5.10 Generic_144488-03 sun4u sparc SUNW.
Client/Server load balancing was implemented across the web and form servers. The system was load tested using a third party tool called HP Load Runner version 11.03 from HP; the transactions were recorded and correspondingly correlated to do dynamic load balancing. HTTP/S was used to enable secure transfer of data over SSL for some of the web pages.
Responsibilities: 
•	Gathered business requirement, studied the application and collected the information from Analysts.
•	Identified the functional scenarios to do performance testing.
•	Designed and executed Test Cases, Generate Test Scripts (Vuser script) and Test scenarios using Loadrunner 9.5.
•	Developed Loadrunner scripts in Web (http/html), Oracle NCA and Oracle Web Application 11i Protocols.
•	Created customized Loadrunner VuGen scripts at API level with manual correlation, user defined functions, and error handling.
•	Enhanced Vuser scripts by adding correlations, parameters, condition controls, and checking/validation functions.
•	Designed and executed the Loadrunner scenarios as per schedule.
•	Prepared the Reports based on the Analysis Generation.
•	Compared it with the benchmark given by client.
•	Involved in Bug reporting using the bug-tracking tool.
•	Involved in Retesting & Regression testing.
•	Prepared summary reports and Traceability Matrix.
